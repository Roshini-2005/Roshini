FileName: "MultipleFiles/new2.py"
import streamlit as st
from PIL import Image
import numpy as np
import tensorflow as tf  # Assuming you'll use TensorFlow for your model
from gtts import gTTS
import os
import time
import base64  # For embedding audio in Streamlit
import re  # For more flexible command parsing

# --- Configuration ---
AUDIO_FILE_PATH = "voice_response.mp3"

# --- Translations for multilingual support ---
translations = {
    "en": {
        "appTitle": "Crop Disease Detector",
        "appSubtitle": "Upload a photo of your crop to detect diseases and get solutions",
        "uploadInstructions": "Drag & drop your crop image here or click to select",
        "uploadBtn": "Select Image",
        "analyzeBtn": "Analyze Image",
        "analysisTitle": "Analysis Results",
        "identifiedDisease": "Identified Disease",
        "confidence": "Confidence",
        "symptoms": "Symptoms",
        "chemicalTreatment": "Chemical Treatment",
        "organicTreatment": "Organic Treatment",
        "prevention": "Prevention",
        "footerText": "┬й 2023 Crop Disease Detector | Helping farmers protect their crops",
        "voiceAssistantTitle": "Voice Assistant (Text-based Simulation)",
        "typeCommand": "Type your command here (e.g., 'upload image', 'what are the symptoms of leaf rust?', 'change language to Spanish'):",
        "processing": "Processing your command...",
        "analysisComplete": "Analysis complete. Disease detected: {disease_name} with {confidence} confidence.",
        "selectImagePrompt": "Please select your crop image for analysis.",
        "displayingHeatmap": "Displaying disease heatmap analysis.",
        "showingSolutions": "Here are the recommended solutions for the detected disease.",
        "unrecognizedCommand": "I didn't understand that. Can you please rephrase or ask about symptoms, treatments, or prevention?",
        "languageChanged": "Language changed to {lang_name}.",
        "languageNotSupported": "Sorry, {lang_name} is not supported. Supported languages are English, Spanish, French, Hindi, Chinese, and Tamil.",
        "voiceCommandsList": "Available commands:\n- 'upload image'\n- 'show solutions'\n- 'change language to [language name]'\n- 'what are the symptoms [of disease]?'\n- 'tell me about chemical treatment [for disease]'\n- 'how to prevent [disease]'\n- 'hello', 'thank you', 'goodbye'",
        "invalidImageWarning": "Please upload only leaf or crop images for analysis."  # New warning message
    },
    "te": {  # Telugu Translation
        "appTitle": "р░кр░Вр░Я р░╡р▒Нр░пр░╛р░зр░┐ р░бр░┐р░Яр▒Жр░Хр▒Нр░Яр░░р▒Н",
        "appSubtitle": "р░╡р▒Нр░пр░╛р░зр▒Бр░▓р░ир▒Б р░Чр▒Бр░░р▒Нр░др░┐р░Вр░Ър░бр░╛р░ир░┐р░Хр░┐ р░ор░░р░┐р░пр▒Б р░кр░░р░┐р░╖р▒Нр░Хр░╛р░░р░╛р░▓р░ир▒Б р░кр▒Кр░Вр░жр░бр░╛р░ир░┐р░Хр░┐ р░ор▒А р░кр░Вр░Я р░лр▒Лр░Яр▒Лр░ир▒Б р░Ер░кр▒НтАМр░▓р▒Лр░бр▒Н р░Ър▒Зр░пр░Вр░бр░┐",
        "uploadInstructions": "р░ор▒А р░кр░Вр░Я р░Ър░┐р░др▒Нр░░р░╛р░ир▒Нр░ир░┐ р░Зр░Хр▒Нр░Хр░бр░Хр▒Б р░▓р░╛р░Чр░Вр░бр░┐ р░▓р▒Зр░жр░╛ р░Ор░Вр░Ър▒Бр░Хр▒Лр░╡р░бр░╛р░ир░┐р░Хр░┐ р░Хр▒Нр░▓р░┐р░Хр▒Н р░Ър▒Зр░пр░Вр░бр░┐",
        "uploadBtn": "р░Ър░┐р░др▒Нр░░р░╛р░ир▒Нр░ир░┐ р░Ор░Вр░Ър▒Бр░Хр▒Лр░Вр░бр░┐",
        "analyzeBtn": "р░Ър░┐р░др▒Нр░░р░╛р░ир▒Нр░ир░┐ р░╡р░┐р░╢р▒Нр░▓р▒Зр░╖р░┐р░Вр░Ър░Вр░бр░┐",
        "analysisTitle": "р░╡р░┐р░╢р▒Нр░▓р▒Зр░╖р░г р░лр░▓р░┐р░др░╛р░▓р▒Б",
        "identifiedDisease": "р░Чр▒Бр░░р▒Нр░др░┐р░Вр░Ър░мр░бр░┐р░и р░╡р▒Нр░пр░╛р░зр░┐",
        "confidence": "р░╡р░┐р░╢р▒Нр░╡р░╛р░╕р░В",
        "symptoms": "р░▓р░Хр▒Нр░╖р░гр░╛р░▓р▒Б",
        "chemicalTreatment": "р░░р░╕р░╛р░пр░и р░Ър░┐р░Хр░┐р░др▒Нр░╕",
        "organicTreatment": "р░╕р▒Зр░Вр░жр▒Нр░░р▒Ар░п р░Ър░┐р░Хр░┐р░др▒Нр░╕",
        "prevention": "р░ир░┐р░╡р░╛р░░р░г",
        "footerText": "┬й 2023 р░кр░Вр░Я р░╡р▒Нр░пр░╛р░зр░┐ р░бр░┐р░Яр▒Жр░Хр▒Нр░Яр░░р▒Н | р░░р▒Ир░др▒Бр░▓р▒Б р░др░о р░кр░Вр░Яр░▓р░ир▒Б р░░р░Хр▒Нр░╖р░┐р░Вр░Ър▒Бр░Хр▒Лр░╡р░бр░╛р░ир░┐р░Хр░┐ р░╕р░╣р░╛р░пр░кр░бр▒Бр░др▒Бр░Вр░жр░┐",
        "voiceAssistantTitle": "р░╡р░╛р░пр░┐р░╕р▒Н р░Ер░╕р░┐р░╕р▒Нр░Яр▒Жр░Вр░Яр▒Н (р░Яр▒Жр░Хр▒Нр░╕р▒Нр░Яр▒Н р░Жр░зр░╛р░░р░┐р░д р░╕р░┐р░ор▒Нр░пр▒Бр░▓р▒Зр░╖р░ир▒Н)",
        "typeCommand": "р░ор▒А р░Жр░жр▒Зр░╢р░╛р░ир▒Нр░ир░┐ р░Зр░Хр▒Нр░Хр░б р░Яр▒Ир░кр▒Н р░Ър▒Зр░пр░Вр░бр░┐ (р░Йр░жр░╛. 'р░Ър░┐р░др▒Нр░░р░╛р░ир▒Нр░ир░┐ р░Ер░кр▒НтАМр░▓р▒Лр░бр▒Н р░Ър▒Зр░пр░Вр░бр░┐', 'р░Жр░Хр▒Б р░др▒Бр░кр▒Нр░кр▒Б р░▓р░Хр▒Нр░╖р░гр░╛р░▓р▒Б р░Пр░ор░┐р░Яр░┐?', 'р░нр░╛р░╖р░ир▒Б р░╕р▒Нр░кр░╛р░ир░┐р░╖р▒НтАМр░Хр▒Б р░ор░╛р░░р▒Нр░Ър░Вр░бр░┐'):",
        "processing": "р░ор▒А р░Жр░жр▒Зр░╢р░╛р░ир▒Нр░ир░┐ р░кр▒Нр░░р░╛р░╕р▒Жр░╕р▒Н р░Ър▒Зр░╕р▒Нр░др▒Лр░Вр░жр░┐...",
        "analysisComplete": "р░╡р░┐р░╢р▒Нр░▓р▒Зр░╖р░г р░кр▒Вр░░р▒Нр░др░пр░┐р░Вр░жр░┐. р░Чр▒Бр░░р▒Нр░др░┐р░Вр░Ър░мр░бр░┐р░и р░╡р▒Нр░пр░╛р░зр░┐: {disease_name} {confidence} р░╡р░┐р░╢р▒Нр░╡р░╛р░╕р░Вр░др▒Л.",
        "selectImagePrompt": "р░жр░пр░Ър▒Зр░╕р░┐ р░╡р░┐р░╢р▒Нр░▓р▒Зр░╖р░г р░Хр▒Лр░╕р░В р░ор▒А р░кр░Вр░Я р░Ър░┐р░др▒Нр░░р░╛р░ир▒Нр░ир░┐ р░Ор░Вр░Ър▒Бр░Хр▒Лр░Вр░бр░┐.",
        "displayingHeatmap": "р░╡р▒Нр░пр░╛р░зр░┐ р░╣р▒Ар░Яр▒НтАМр░ор▒Нр░пр░╛р░кр▒Н р░╡р░┐р░╢р▒Нр░▓р▒Зр░╖р░гр░ир▒Б р░кр▒Нр░░р░жр░░р▒Нр░╢р░┐р░╕р▒Нр░др▒Лр░Вр░жр░┐.",
        "showingSolutions": "р░Чр▒Бр░░р▒Нр░др░┐р░Вр░Ър░мр░бр░┐р░и р░╡р▒Нр░пр░╛р░зр░┐р░Хр░┐ р░╕р░┐р░лр░╛р░░р▒Нр░╕р▒Б р░Ър▒Зр░пр░мр░бр░┐р░и р░кр░░р░┐р░╖р▒Нр░Хр░╛р░░р░╛р░▓р▒Б р░Зр░Хр▒Нр░Хр░б р░Йр░ир▒Нр░ир░╛р░пр░┐.",
        "unrecognizedCommand": "р░ир░╛р░Хр▒Б р░Ер░жр░┐ р░Ер░░р▒Нр░ер░В р░Хр░╛р░▓р▒Зр░жр▒Б. р░жр░пр░Ър▒Зр░╕р░┐ р░ор░│р▒Нр░│р▒А р░Ър▒Жр░кр▒Нр░кр░Чр░▓р░░р░╛ р░▓р▒Зр░жр░╛ р░▓р░Хр▒Нр░╖р░гр░╛р░▓р▒Б, р░Ър░┐р░Хр░┐р░др▒Нр░╕р░▓р▒Б р░▓р▒Зр░жр░╛ р░ир░┐р░╡р░╛р░░р░г р░Чр▒Бр░░р░┐р░Вр░Ър░┐ р░Ер░бр░Чр░Чр░▓р░░р░╛?",
        "languageChanged": "р░нр░╛р░╖ {lang_name} р░Хр▒Б р░ор░╛р░░р▒Нр░Ър░мр░бр░┐р░Вр░жр░┐.",
        "languageNotSupported": "р░Хр▒Нр░╖р░ор░┐р░Вр░Ър░Вр░бр░┐, {lang_name} р░ор░жр▒Нр░жр░др▒Б р░▓р▒Зр░жр▒Б. р░ор░жр▒Нр░жр░др▒Б р░Йр░ир▒Нр░и р░нр░╛р░╖р░▓р▒Б р░Зр░Вр░Чр▒Нр░▓р▒Ар░╖р▒Н, р░╕р▒Нр░кр░╛р░ир░┐р░╖р▒Н, р░лр▒Нр░░р▒Жр░Вр░Ър▒Н, р░╣р░┐р░Вр░жр▒А, р░Ър▒Ир░ир▒Ар░╕р▒Н р░ор░░р░┐р░пр▒Б р░др░ор░┐р░│р░В.",
        "voiceCommandsList": "р░Ер░Вр░жр▒Бр░мр░╛р░Яр▒Бр░▓р▒Л р░Йр░ир▒Нр░и р░Жр░жр▒Зр░╢р░╛р░▓р▒Б:\n- 'р░Ър░┐р░др▒Нр░░р░╛р░ир▒Нр░ир░┐ р░Ер░кр▒НтАМр░▓р▒Лр░бр▒Н р░Ър▒Зр░пр░Вр░бр░┐'\n- 'р░кр░░р░┐р░╖р▒Нр░Хр░╛р░░р░╛р░▓р░ир▒Б р░Ър▒Вр░кр░┐р░Вр░Ър▒Б'\n- 'р░нр░╛р░╖р░ир▒Б [р░нр░╛р░╖ р░кр▒Зр░░р▒Б] р░Хр▒Б р░ор░╛р░░р▒Нр░Ър░Вр░бр░┐'\n- '[р░╡р▒Нр░пр░╛р░зр░┐] р░▓р░Хр▒Нр░╖р░гр░╛р░▓р▒Б р░Пр░ор░┐р░Яр░┐?'\n- '[р░╡р▒Нр░пр░╛р░зр░┐] р░░р░╕р░╛р░пр░и р░Ър░┐р░Хр░┐р░др▒Нр░╕ р░Чр▒Бр░░р░┐р░Вр░Ър░┐ р░Ър▒Жр░кр▒Нр░кр░Вр░бр░┐'\n- '[р░╡р▒Нр░пр░╛р░зр░┐] р░Ор░▓р░╛ р░ир░┐р░╡р░╛р░░р░┐р░Вр░Ър░╛р░▓р░┐?'\n- 'р░╣р░▓р▒Л', 'р░зр░ир▒Нр░пр░╡р░╛р░жр░╛р░▓р▒Б', 'р░╡р▒Ар░бр▒Нр░Хр▒Лр░▓р▒Б'",
        "invalidImageWarning": "р░жр░пр░Ър▒Зр░╕р░┐ р░╡р░┐р░╢р▒Нр░▓р▒Зр░╖р░г р░Хр▒Лр░╕р░В р░Жр░Хр▒Б р░▓р▒Зр░жр░╛ р░кр░Вр░Я р░Ър░┐р░др▒Нр░░р░╛р░▓р░ир▒Б р░ор░╛р░др▒Нр░░р░ор▒З р░Ер░кр▒НтАМр░▓р▒Лр░бр▒Н р░Ър▒Зр░пр░Вр░бр░┐."
    },
    "hi": {
        "appTitle": "рдлрд╕рд▓ рд░реЛрдЧ рдбрд┐рдЯреЗрдХреНрдЯрд░",
        "appSubtitle": "рд░реЛрдЧреЛрдВ рдХрд╛ рдкрддрд╛ рд▓рдЧрд╛рдиреЗ рдФрд░ рд╕рдорд╛рдзрд╛рди рдкреНрд░рд╛рдкреНрдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдЕрдкрдиреА рдлрд╕рд▓ рдХреА рдПрдХ рддрд╕реНрд╡реАрд░ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ",
        "uploadInstructions": "рдЕрдкрдиреА рдлрд╕рд▓ рдЫрд╡рд┐ рдХреЛ рдпрд╣рд╛рдВ рдЦреАрдВрдЪреЗрдВ рдФрд░ рдЫреЛрдбрд╝реЗрдВ рдпрд╛ рдЪрдпрди рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдХреНрд▓рд┐рдХ рдХрд░реЗрдВ",
        "uploadBtn": "рдЫрд╡рд┐ рдЪреБрдиреЗрдВ",
        "analyzeBtn": "рдЫрд╡рд┐ рдХрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХрд░реЗрдВ",
        "analysisTitle": "рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдкрд░рд┐рдгрд╛рдо",
        "identifiedDisease": "рдкрд╣рдЪрд╛рдиреА рдЧрдИ рдмреАрдорд╛рд░реА",
        "confidence": "рд╡рд┐рд╢реНрд╡рд╛рд╕",
        "symptoms": "рд▓рдХреНрд╖рдг",
        "chemicalTreatment": "рд░рд╛рд╕рд╛рдпрдирд┐рдХ рдЙрдкрдЪрд╛рд░",
        "organicTreatment": "рдЬреИрд╡рд┐рдХ рдЙрдкрдЪрд╛рд░",
        "prevention": "рдирд┐рд╡рд╛рд░рдг",
        "footerText": "┬й 2023 рдлрд╕рд▓ рд░реЛрдЧ рдбрд┐рдЯреЗрдХреНрдЯрд░ | рдХрд┐рд╕рд╛рдиреЛрдВ рдХреЛ рдЕрдкрдиреА рдлрд╕рд▓реЛрдВ рдХреА рд░рдХреНрд╖рд╛ рдХрд░рдиреЗ рдореЗрдВ рдорджрдж рдХрд░рдирд╛",
        "voiceAssistantTitle": "рд╡реЙрдпрд╕ рдЕрд╕рд┐рд╕реНрдЯреЗрдВрдЯ (рдЯреЗрдХреНрд╕реНрдЯ-рдЖрдзрд╛рд░рд┐рдд рд╕рд┐рдореБрд▓реЗрд╢рди)",
        "typeCommand": "рдЕрдкрдирд╛ рдХрдорд╛рдВрдб рдпрд╣рд╛рдВ рдЯрд╛рдЗрдк рдХрд░реЗрдВ (рдЙрджрд╛. 'рдЫрд╡рд┐ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ', 'рдкрддреНрддреА рдХреЗ рдЬрдВрдЧ рдХреЗ рд▓рдХреНрд╖рдг рдХреНрдпрд╛ рд╣реИрдВ?', 'рднрд╛рд╖рд╛ рдмрджрд▓реЗрдВ рд╕реНрдкреЗрдирд┐рд╢ рдореЗрдВ'):",
        "processing": "рдЖрдкрдХреЗ рдХрдорд╛рдВрдб рдХреЛ рд╕рдВрд╕рд╛рдзрд┐рдд рдХрд┐рдпрд╛ рдЬрд╛ рд░рд╣рд╛ рд╣реИ...",
        "analysisComplete": "рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдкреВрд░рд╛ рд╣реБрдЖред рдмреАрдорд╛рд░реА рдХрд╛ рдкрддрд╛ рдЪрд▓рд╛: {disease_name} {confidence} рд╡рд┐рд╢реНрд╡рд╛рд╕ рдХреЗ рд╕рд╛рдеред",
        "selectImagePrompt": "рдХреГрдкрдпрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХреЗ рд▓рд┐рдП рдЕрдкрдиреА рдлрд╕рд▓ рдХреА рдЫрд╡рд┐ рдХрд╛ рдЪрдпрди рдХрд░реЗрдВред",
        "displayingHeatmap": "рд░реЛрдЧ рд╣реАрдЯрдореИрдк рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдкреНрд░рджрд░реНрд╢рд┐рдд рдХрд┐рдпрд╛ рдЬрд╛ рд░рд╣рд╛ рд╣реИред",
        "showingSolutions": "рдпрд╣рд╛рдВ рдкрддрд╛ рдЪрд▓реЗ рд░реЛрдЧ рдХреЗ рд▓рд┐рдП рдЕрдиреБрд╢рдВрд╕рд┐рдд рд╕рдорд╛рдзрд╛рди рджрд┐рдП рдЧрдП рд╣реИрдВред",
        "unrecognizedCommand": "рдореБрдЭреЗ рд╡рд╣ рд╕рдордЭ рдирд╣реАрдВ рдЖрдпрд╛ред рдХреНрдпрд╛ рдЖрдк рдЗрд╕реЗ рдлрд┐рд░ рд╕реЗ рдХрд╣ рд╕рдХрддреЗ рд╣реИрдВ рдпрд╛ рд▓рдХреНрд╖рдгреЛрдВ, рдЙрдкрдЪрд╛рд░реЛрдВ рдпрд╛ рд░реЛрдХрдерд╛рдо рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдкреВрдЫ рд╕рдХрддреЗ рд╣реИрдВ?",
        "languageChanged": "рднрд╛рд╖рд╛ {lang_name} рдореЗрдВ рдмрджрд▓ рджреА рдЧрдИред",
        "languageNotSupported": "рдХреНрд╖рдорд╛ рдХрд░реЗрдВ, {lang_name} рд╕рдорд░реНрдерд┐рдд рдирд╣реАрдВ рд╣реИред рд╕рдорд░реНрдерд┐рдд рднрд╛рд╖рд╛рдПрдБ рдЕрдВрдЧреНрд░реЗрдЬреА, рд╕реНрдкреЗрдирд┐рд╢, рдлреНрд░реЗрдВрдЪ, рд╣рд┐рдВрджреА, рдЪреАрдиреА рдФрд░ рддрдорд┐рд▓ рд╣реИрдВред",
        "voiceCommandsList": "рдЙрдкрд▓рдмреНрдз рдХрдорд╛рдВрдб:\n- 'рдЫрд╡рд┐ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ'\n- 'рд╕рдорд╛рдзрд╛рди рджрд┐рдЦрд╛рдПрдВ'\n- 'рднрд╛рд╖рд╛ рдмрджрд▓реЗрдВ [рднрд╛рд╖рд╛ рдХрд╛ рдирд╛рдо]'\n- 'рд▓рдХреНрд╖рдг рдХреНрдпрд╛ рд╣реИрдВ [рд░реЛрдЧ рдХреЗ]?'\n- 'рд░рд╛рд╕рд╛рдпрдирд┐рдХ рдЙрдкрдЪрд╛рд░ рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдмрддрд╛рдПрдВ [рд░реЛрдЧ рдХреЗ рд▓рд┐рдП]'\n- 'рдХреИрд╕реЗ рд░реЛрдХреЗрдВ [рд░реЛрдЧ]'\n- 'рдирдорд╕реНрддреЗ', 'рдзрдиреНрдпрд╡рд╛рдж', 'рдЕрд▓рд╡рд┐рджрд╛'",
        "invalidImageWarning": "рдХреГрдкрдпрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХреЗ рд▓рд┐рдП рдХреЗрд╡рд▓ рдкрддреНрддреА рдпрд╛ рдлрд╕рд▓ рдХреА рдЫрд╡рд┐рдпрд╛рдВ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ."
    },
    "ta": {
        "appTitle": "рокропро┐ро░рпН роирпЛропрпН роХрогрпНроЯро▒ро┐родро▓рпН",
        "appSubtitle": "роирпЛропрпНроХро│рпИроХрпН роХрогрпНроЯро▒ро┐роирпНродрпБ родрпАро░рпНро╡рпБроХро│рпИрокрпН рокрпЖро▒ роЙроЩрпНроХро│рпН рокропро┐ро░ро┐ройрпН рокрпБроХрпИрокрпНрокроЯродрпНродрпИрокрпН рокродро┐ро╡рпЗро▒рпНро▒ро╡рпБроорпН",
        "uploadInstructions": "роЙроЩрпНроХро│рпН рокропро┐ро░рпН рокроЯродрпНродрпИ роЗроЩрпНроХрпЗ роЗро┤рпБродрпНродрпБ ро╡ро┐роЯро╡рпБроорпН роЕро▓рпНро▓родрпБ родрпЗро░рпНроирпНродрпЖроЯрпБроХрпНроХ роХро┐ро│ро┐роХрпН роЪрпЖропрпНропро╡рпБроорпН",
        "uploadBtn": "рокроЯродрпНродрпИродрпН родрпЗро░рпНроирпНродрпЖроЯрпБроХрпНроХро╡рпБроорпН",
        "analyzeBtn": "рокроЯродрпНродрпИ рокроХрпБрокрпНрокро╛ропрпНро╡рпБ роЪрпЖропрпНропро╡рпБроорпН",
        "analysisTitle": "рокроХрпБрокрпНрокро╛ропрпНро╡рпБ роорпБроЯро┐ро╡рпБроХро│рпН",
        "identifiedDisease": "роХрогрпНроЯро▒ро┐ропрокрпНрокроЯрпНроЯ роирпЛропрпН",
        "confidence": "роироорпНрокро┐роХрпНроХрпИ",
        "symptoms": "роЕро▒ро┐роХрпБро▒ро┐роХро│рпН",
        "chemicalTreatment": "роЗро░роЪро╛ропрой роЪро┐роХро┐роЪрпНроЪрпИ",
        "organicTreatment": "роЗропро▒рпНроХрпИ роЪро┐роХро┐роЪрпНроЪрпИ",
        "prevention": "родроЯрпБрокрпНрокрпБ",
        "footerText": "┬й 2023 рокропро┐ро░рпН роирпЛропрпН роХрогрпНроЯро▒ро┐родро▓рпН | ро╡ро┐ро╡роЪро╛ропро┐роХро│рпН родроЩрпНроХро│рпН рокропро┐ро░рпНроХро│рпИрокрпН рокро╛родрпБроХро╛роХрпНроХ роЙродро╡рпБроХро┐ро▒родрпБ",
        "voiceAssistantTitle": "роХрпБро░ро▓рпН роЙродро╡ро┐ропро╛ро│ро░рпН (роЙро░рпИ роЕроЯро┐рокрпНрокроЯрпИропро┐ро▓ро╛рой роЙро░рпБро╡роХрокрпНрокроЯрпБродрпНродрпБродро▓рпН)",
        "typeCommand": "роЙроЩрпНроХро│рпН роХроЯрпНроЯро│рпИропрпИ роЗроЩрпНроХрпЗ родроЯрпНроЯроЪрпНроЪрпБ роЪрпЖропрпНропро╡рпБроорпН (роО.роХро╛., 'рокроЯродрпНродрпИрокрпН рокродро┐ро╡рпЗро▒рпНро▒ро╡рпБроорпН', 'роЗро▓рпИ родрпБро░рпБ роирпЛропро┐ройрпН роЕро▒ро┐роХрпБро▒ро┐роХро│рпН роОройрпНрой?', 'роорпКро┤ро┐ропрпИ ро╕рпНрокро╛ройро┐ро╖рпН роЖроХ рооро╛ро▒рпНро▒ро╡рпБроорпН'):",
        "processing": "роЙроЩрпНроХро│рпН роХроЯрпНроЯро│рпИропрпИроЪрпН роЪрпЖропро▓ро╛роХрпНроХрпБроХро┐ро▒родрпБ...",
        "analysisComplete": "рокроХрпБрокрпНрокро╛ропрпНро╡рпБ роорпБроЯро┐роирпНродродрпБ. роХрогрпНроЯро▒ро┐ропрокрпНрокроЯрпНроЯ роирпЛропрпН: {disease_name} {confidence} роироорпНрокро┐роХрпНроХрпИропрпБроЯройрпН.",
        "selectImagePrompt": "рокроХрпБрокрпНрокро╛ропрпНро╡рпБроХрпНроХро╛роХ роЙроЩрпНроХро│рпН рокропро┐ро░рпН рокроЯродрпНродрпИ родрпЗро░рпНроирпНродрпЖроЯрпБроХрпНроХро╡рпБроорпН.",
        "displayingHeatmap": "роирпЛропрпН ро╡рпЖрокрпНрок ро╡ро░рпИрокроЯ рокроХрпБрокрпНрокро╛ропрпНро╡рпИроХрпН роХро╛роЯрпНроЯрпБроХро┐ро▒родрпБ.",
        "showingSolutions": "роХрогрпНроЯро▒ро┐ропрокрпНрокроЯрпНроЯ роирпЛропрпНроХрпНроХро╛рой рокро░ро┐роирпНродрпБро░рпИроХрпНроХрокрпНрокроЯрпНроЯ родрпАро░рпНро╡рпБроХро│рпН роЗроЩрпНроХрпЗ.",
        "unrecognizedCommand": "роОройроХрпНроХрпБ роЕродрпБ рокрпБро░ро┐ропро╡ро┐ро▓рпНро▓рпИ. роирпАроЩрпНроХро│рпН роорпАрогрпНроЯрпБроорпН роХрпВро▒ роорпБроЯро┐ропрпБрооро╛ роЕро▓рпНро▓родрпБ роЕро▒ро┐роХрпБро▒ро┐роХро│рпН, роЪро┐роХро┐роЪрпНроЪрпИроХро│рпН роЕро▓рпНро▓родрпБ родроЯрпБрокрпНрокрпБ рокро▒рпНро▒ро┐ роХрпЗроЯрпНроХ роорпБроЯро┐ропрпБрооро╛?",
        "languageChanged": "роорпКро┤ро┐ {lang_name} роЖроХ рооро╛ро▒рпНро▒рокрпНрокроЯрпНроЯродрпБ.",
        "languageNotSupported": "рооройрпНройро┐роХрпНроХро╡рпБроорпН, {lang_name} роЖродро░ро┐роХрпНроХрокрпНрокроЯро╡ро┐ро▓рпНро▓рпИ. роЖродро░ро┐роХрпНроХрокрпНрокроЯрпБроорпН роорпКро┤ро┐роХро│рпН роЖроЩрпНроХро┐ро▓роорпН, ро╕рпНрокро╛ройро┐ро╖рпН, рокро┐ро░роЮрпНроЪрпБ, роЗроирпНродро┐, роЪрпАройроорпН рооро▒рпНро▒рпБроорпН родрооро┐ро┤рпН.",
        "voiceCommandsList": "роХро┐роЯрпИроХрпНроХрпБроорпН роХроЯрпНроЯро│рпИроХро│рпН:\n- 'рокроЯродрпНродрпИрокрпН рокродро┐ро╡рпЗро▒рпНро▒ро╡рпБроорпН'\n- 'родрпАро░рпНро╡рпБроХро│рпИроХрпН роХро╛роЯрпНроЯрпБ'\n- 'роорпКро┤ро┐ропрпИ [роорпКро┤ро┐ рокрпЖропро░рпН] роЖроХ рооро╛ро▒рпНро▒ро╡рпБроорпН'\n- '[роирпЛропрпН] роЕро▒ро┐роХрпБро▒ро┐роХро│рпН роОройрпНрой?'\n- '[роирпЛропрпН] роЗро░роЪро╛ропрой роЪро┐роХро┐роЪрпНроЪрпИ рокро▒рпНро▒ро┐ роЪрпКро▓рпНро▓рпБроЩрпНроХро│рпН'\n- '[роирпЛропрпН] родроЯрпБрокрпНрокродрпБ роОрокрпНрокроЯро┐?'\n- 'ро╡рогроХрпНроХроорпН', 'роиройрпНро▒ро┐', 'ро╡ро┐роЯрпИрокрпЖро▒рпБроХро┐ро▒рпЗройрпН'",
        "invalidImageWarning": "рокроХрпБрокрпНрокро╛ропрпНро╡рпБроХрпНроХро╛роХ роЗро▓рпИ роЕро▓рпНро▓родрпБ рокропро┐ро░рпН рокроЯроЩрпНроХро│рпИ роороЯрпНроЯрпБроорпЗ рокродро┐ро╡рпЗро▒рпНро▒ро╡рпБроорпН."
    }
}

# --- Session State Initialization ---
if 'current_language' not in st.session_state:
    st.session_state.current_language = 'en'
if 'disease_info' not in st.session_state:
    st.session_state.disease_info = None
if 'uploaded_image' not in st.session_state:
    st.session_state.uploaded_image = None
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'disease_model' not in st.session_state:
    st.session_state.disease_model = None
if 'crop_leaf_detector_model' not in st.session_state:
    st.session_state.crop_leaf_detector_model = None

# --- Helper Functions ---

# Function to speak text using gTTS and embed in Streamlit
def speak_text(text, lang):
    try:
        tts = gTTS(text=text, lang=lang, slow=False)
        tts.save(AUDIO_FILE_PATH)
        with open(AUDIO_FILE_PATH, "rb") as f:
            audio_bytes = f.read()
        audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
        audio_html = f'<audio autoplay="true" src="data:audio/mp3;base64,{audio_base64}"></audio>'
        st.components.v1.html(audio_html, height=0, width=0)
        # Give a small delay to ensure audio playback starts before file deletion
        time.sleep(0.5)
        if os.path.exists(AUDIO_FILE_PATH):
            os.remove(AUDIO_FILE_PATH)  # Clean up the audio file
    except Exception as e:
        st.error(f"Error playing audio: {e}. Please ensure your browser supports audio playback and try again.")

# Function to get translated text
def get_text(key):
    return translations[st.session_state.current_language].get(key, translations["en"][key])

# --- Model Loading (Placeholder) ---
@st.cache_resource  # Cache the model to avoid reloading on every rerun
def load_disease_model():
    """
    Loads the pre-trained crop disease detection model.
    Replace 'path/to/your/disease_model.h5' with the actual path to your model file.
    """
    try:
        # Example: Load a Keras/TensorFlow model
        # model = tf.keras.models.load_model('path/to/your/disease_model.h5')
        # return model
        # For demonstration, returning a dummy object
        st.success("Dummy Disease Model Loaded (replace with actual model)")
        return "dummy_disease_model"
    except Exception as e:
        st.error(f"Error loading disease model: {e}. Make sure the model file exists and is accessible.")
        return None

@st.cache_resource  # Cache the model to avoid reloading on every rerun
def load_crop_leaf_detector_model():
    """
    Loads the pre-trained model to detect if an image is a crop/leaf.
    Replace 'path/to/your/crop_leaf_detector_model.h5' with the actual path.
    """
    try:
        # Example: Load a Keras/TensorFlow model
        # model = tf.keras.models.load_model('path/to/your/crop_leaf_detector_model.h5')
        # return model
        # For demonstration, returning a dummy object
        st.success("Dummy Crop/Leaf Detector Model Loaded (replace with actual model)")
        return "dummy_crop_leaf_detector_model"
    except Exception as e:
        st.error(f"Error loading crop/leaf detector model: {e}. Make sure the model file exists and is accessible.")
        return None

# Initialize models on startup
if st.session_state.disease_model is None:
    st.session_state.disease_model = load_disease_model()
if st.session_state.crop_leaf_detector_model is None:
    st.session_state.crop_leaf_detector_model = load_crop_leaf_detector_model()

# --- Dummy Disease Database (Replace with actual model output mapping) ---
# In a real scenario, your model would output a class index,
# and you'd map that index to this detailed information.
disease_database = {
    "Leaf Rust": {
        "symptoms": "Small, round to oblong yellow spots on leaves that develop into reddish-brown pustules. The pustules are most common on the upper leaf surface and leaf sheaths.",
        "chemical_solution": "Apply fungicides containing propiconazole or tebuconazole at the first sign of disease, repeating every 14 days if conditions remain favorable for disease development.",
        "organic_solution": "Apply neem oil spray every 7-10 days. Remove and destroy infected leaves. Increase airflow and reduce leaf wetness by watering only at the base of plants.",
        "prevention_tips": "Plant resistant varieties when available. Ensure proper spacing (at least 18-24 inches apart) to promote air circulation. Avoid overhead watering. Clean up plant debris at the end of the season. Rotate crops if possible."
    },
    "Early Blight": {
        "symptoms": "Dark, concentric rings (target-like spots) on older leaves, often surrounded by a yellow halo. Can also affect stems and fruits.",
        "chemical_solution": "Fungicides containing chlorothalonil or mancozeb are effective. Apply at first sign of disease and repeat as per label instructions.",
        "organic_solution": "Use copper-based fungicides. Practice crop rotation. Ensure good air circulation. Remove and destroy infected plant parts immediately.",
        "prevention_tips": "Plant resistant varieties. Avoid overhead irrigation. Ensure proper plant spacing. Mulch around plants to prevent soil splash. Rotate crops every 2-3 years."
    },
    "Powdery Mildew": {
        "symptoms": "White, powdery spots on the surface of leaves, stems, and sometimes flowers. These spots can spread and cover entire leaves.",
        "chemical_solution": "Apply fungicides like myclobutanil or propiconazole. Ensure thorough coverage of affected areas.",
        "organic_solution": "Spray with a mixture of baking soda (1 tsp per liter of water) and a few drops of liquid soap. Neem oil is also effective. Ensure good air circulation.",
        "prevention_tips": "Plant resistant varieties. Provide good air circulation. Avoid excessive nitrogen fertilization. Water plants at the base to keep leaves dry."
    },
    "Healthy": {
        "symptoms": "Leaves are vibrant green, firm, and show no signs of discoloration, spots, or wilting. Plant growth is vigorous and uniform.",
        "chemical_solution": "No chemical treatment needed. Continue good agricultural practices.",
        "organic_solution": "No organic treatment needed. Maintain healthy soil and plant conditions.",
        "prevention_tips": "Continue with optimal watering, fertilization, and pest management. Monitor regularly for any early signs of stress or disease."
    }
}

# --- Placeholder for actual prediction logic ---
def predict_disease(image):
    """
    Simulates disease prediction. In a real app, this would use st.session_state.disease_model.
    Returns a tuple: (disease_name, confidence)
    """
    if st.session_state.disease_model == "dummy_disease_model":
        # Simulate different outcomes for demonstration
        if np.random.rand() < 0.7: # 70% chance of a disease
            diseases = list(disease_database.keys())
            diseases.remove("Healthy") # Don't randomly pick healthy if it's a disease
            predicted_disease = np.random.choice(diseases)
            confidence = round(0.7 + np.random.rand() * 0.2, 2) # 70-90% confidence
        else:
            predicted_disease = "Healthy"
            confidence = round(0.8 + np.random.rand() * 0.15, 2) # 80-95% confidence
        return predicted_disease, confidence
    else:
        # Here you would preprocess the image and feed it to your actual model
        # For example:
        # img = image.resize((224, 224)) # Resize for model input
        # img_array = np.array(img) / 255.0 # Normalize
        # img_array = np.expand_dims(img_array, axis=0) # Add batch dimension
        # predictions = st.session_state.disease_model.predict(img_array)
        # predicted_class_index = np.argmax(predictions)
        # confidence = np.max(predictions)
        # disease_name = your_class_labels[predicted_class_index]
        # return disease_name, confidence
        st.warning("Disease model not properly loaded. Using dummy prediction.")
        return "Unknown Disease", 0.5

def is_crop_leaf_image(image):
    """
    Simulates checking if the uploaded image is a crop or leaf.
    In a real app, this would use st.session_state.crop_leaf_detector_model.
    """
    if st.session_state.crop_leaf_detector_model == "dummy_crop_leaf_detector_model":
        # Simulate a check: assume it's a crop/leaf for now
        return True
    else:
        # Here you would preprocess the image and feed it to your actual detector model
        # For example:
        # img = image.resize((128, 128))
        # img_array = np.array(img) / 255.0
        # img_array = np.expand_dims(img_array, axis=0)
        # prediction = st.session_state.crop_leaf_detector_model.predict(img_array)
        # return prediction[0][0] > 0.5 # Assuming binary classification (crop/leaf vs. not)
        st.warning("Crop/Leaf detector model not properly loaded. Assuming image is valid.")
        return True

# --- Voice Assistant Command Processing ---
def process_command(command):
    command = command.lower().strip()
    response = ""
    lang = st.session_state.current_language

    if "upload image" in command:
        response = get_text("selectImagePrompt")
        # In a real app, you might trigger a file uploader or guide the user
        st.session_state.chat_history.append(f"**You:** {command}")
        st.session_state.chat_history.append(f"**Assistant:** {response}")
        speak_text(response, lang)
        return

    if "show solutions" in command:
        if st.session_state.disease_info:
            disease_name = st.session_state.disease_info["name"]
            response = get_text("showingSolutions").format(disease_name=disease_name)
            st.session_state.chat_history.append(f"**You:** {command}")
            st.session_state.chat_history.append(f"**Assistant:** {response}")
            speak_text(response, lang)
            # Display solutions in the main UI
            st.session_state.show_solutions = True
        else:
            response = get_text("selectImagePrompt") # Or "No disease analyzed yet."
            st.session_state.chat_history.append(f"**You:** {command}")
            st.session_state.chat_history.append(f"**Assistant:** {response}")
            speak_text(response, lang)
        return

    if "change language to" in command:
        match = re.search(r"change language to (\w+)", command)
        if match:
            lang_name = match.group(1).lower()
            supported_langs = {
                "english": "en", "spanish": "es", "french": "fr",
                "hindi": "hi", "chinese": "zh-cn", "tamil": "ta",
                "telugu": "te" # Added Telugu
            }
            if lang_name in supported_langs:
                st.session_state.current_language = supported_langs[lang_name]
                response = get_text("languageChanged").format(lang_name=lang_name.capitalize())
                st.session_state.chat_history.append(f"**You:** {command}")
                st.session_state.chat_history.append(f"**Assistant:** {response}")
                speak_text(response, st.session_state.current_language)
                st.experimental_rerun() # Rerun to update UI with new language
            else:
                response = get_text("languageNotSupported").format(lang_name=lang_name.capitalize())
                st.session_state.chat_history.append(f"**You:** {command}")
                st.session_state.chat_history.append(f"**Assistant:** {response}")
                speak_text(response, lang)
        else:
            response = get_text("unrecognizedCommand")
            st.session_state.chat_history.append(f"**You:** {command}")
            st.session_state.chat_history.append(f"**Assistant:** {response}")
            speak_text(response, lang)
        return

    # Commands related to disease info (symptoms, chemical, organic, prevention)
    disease_match = re.search(r"(symptoms|chemical treatment|organic treatment|prevent) (?:of|for)?\s*(.*)", command)
    if disease_match:
        info_type = disease_match.group(1)
        disease_query = disease_match.group(2).strip()

        # Try to find the disease in the database, prioritizing exact match or current detected disease
        target_disease = None
        if disease_query:
            for d_name in disease_database:
                if disease_query.lower() in d_name.lower():
                    target_disease = d_name
                    break
        elif st.session_state.disease_info:
            target_disease = st.session_state.disease_info["name"]

        if target_disease and target_disease in disease_database:
            info = disease_database[target_disease]
            if info_type == "symptoms":
                response = f"{target_disease} {get_text('symptoms').lower()}: {info['symptoms']}"
            elif info_type == "chemical treatment":
                response = f"{target_disease} {get_text('chemicalTreatment').lower()}: {info['chemical_solution']}"
            elif info_type == "organic treatment":
                response = f"{target_disease} {get_text('organicTreatment').lower()}: {info['organic_solution']}"
            elif info_type == "prevent":
                response = f"{target_disease} {get_text('prevention').lower()}: {info['prevention_tips']}"
            else:
                response = get_text("unrecognizedCommand")
        else:
            response = f"I don't have information for '{disease_query}' or no disease has been detected yet. Please specify a known disease or analyze an image first."
        st.session_state.chat_history.append(f"**You:** {command}")
        st.session_state.chat_history.append(f"**Assistant:** {response}")
        speak_text(response, lang)
        return

    if "hello" in command:
        response = "Hello! How can I assist you today?"
        st.session_state.chat_history.append(f"**You:** {command}")
        st.session_state.chat_history.append(f"**Assistant:** {response}")
        speak_text(response, lang)
        return

    if "thank you" in command or "thanks" in command:
        response = "You're welcome! Is there anything else I can help with?"
        st.session_state.chat_history.append(f"**You:** {command}")
        st.session_state.chat_history.append(f"**Assistant:** {response}")
        speak_text(response, lang)
        return

    if "goodbye" in command or "bye" in command:
        response = "Goodbye! Have a great day."
        st.session_state.chat_history.append(f"**You:** {command}")
        st.session_state.chat_history.append(f"**Assistant:** {response}")
        speak_text(response, lang)
        return

    response = get_text("unrecognizedCommand")
    st.session_state.chat_history.append(f"**You:** {command}")
    st.session_state.chat_history.append(f"**Assistant:** {response}")
    speak_text(response, lang)


# Define a callback function to handle the command and clear the input
# This function is placed here, after process_command and before the UI layout,
# which is a good logical place for helper functions.
def handle_command_and_clear():
    if st.session_state.command_input:
        process_command(st.session_state.command_input)
        # Clear the text input by setting its session state key to an empty string
        # This works because it's done within a callback, before the next rerun.
        st.session_state.command_input = ""


# --- Streamlit UI Layout ---
st.set_page_config(
    page_title=get_text("appTitle"),
    page_icon="ЁЯМ┐",
    layout="wide"
)

# Custom CSS for better aesthetics
st.markdown("""
    <style>
    .main-header {
        font-size: 3em;
        color: #28a745;
        text-align: center;
        margin-bottom: 0.5em;
    }
    .subheader {
        font-size: 1.5em;
        color: #6c757d;
        text-align: center;
        margin-bottom: 1.5em;
    }
    .stFileUploader > div > div > button {
        background-color: #28a745;
        color: white;
        border-radius: 0.5em;
        padding: 0.5em 1em;
    }
    .stButton > button {
        background-color: #007bff;
        color: white;
        border-radius: 0.5em;
        padding: 0.5em 1em;
    }
    .stButton > button:hover {
        background-color: #0056b3;
    }
    .analysis-section {
        border: 1px solid #e0e0e0;
        border-radius: 0.5em;
        padding: 1.5em;
        margin-top: 2em;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    }
    .chat-container {
        border: 1px solid #e0e0e0;
        border-radius: 0.5em;
        padding: 1em;
        height: 300px;
        overflow-y: auto;
        background-color: #f8f9fa;
    }
    .chat-message {
        margin-bottom: 0.5em;
    }
    .chat-message.user {
        text-align: right;
        color: #007bff;
    }
    .chat-message.assistant {
        text-align: left;
        color: #28a745;
    }
    </style>
    """, unsafe_allow_html=True)

st.markdown(f"<h1 class='main-header'>{get_text('appTitle')}</h1>", unsafe_allow_html=True)
st.markdown(f"<p class='subheader'>{get_text('appSubtitle')}</p>", unsafe_allow_html=True)

# Language selection in sidebar
st.sidebar.header("Language / р░нр░╛р░╖ / рднрд╛рд╖рд╛")
lang_options = {
    "English": "en",
    "р░др▒Жр░▓р▒Бр░Чр▒Б (Telugu)": "te",
    "рд╣рд┐рдВрджреА (Hindi)": "hi",
    "родрооро┐ро┤рпН (Tamil)": "ta"
}
selected_lang_name = st.sidebar.selectbox(
    "Select Language",
    options=list(lang_options.keys()),
    index=list(lang_options.values()).index(st.session_state.current_language),
    format_func=lambda x: x # Display full name in selectbox
)
if lang_options[selected_lang_name] != st.session_state.current_language:
    st.session_state.current_language = lang_options[selected_lang_name]
    st.experimental_rerun() # Rerun to apply language change

# Main content area
col1, col2 = st.columns([2, 1])

with col1:
    st.header(get_text("uploadInstructions"))
    uploaded_file = st.file_uploader(get_text("uploadBtn"), type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        st.session_state.uploaded_image = Image.open(uploaded_file)
        st.image(st.session_state.uploaded_image, caption="Uploaded Image", use_column_width=True)

        if st.button(get_text("analyzeBtn")):
            if st.session_state.uploaded_image:
                # Check if it's a crop/leaf image first
                if is_crop_leaf_image(st.session_state.uploaded_image):
                    with st.spinner(get_text("processing")):
                        disease_name, confidence = predict_disease(st.session_state.uploaded_image)
                        st.session_state.disease_info = {
                            "name": disease_name,
                            "confidence": confidence,
                            "details": disease_database.get(disease_name, {})
                        }
                        st.success(get_text("analysisComplete").format(
                            disease_name=disease_name,
                            confidence=f"{confidence*100:.2f}%"
                        ))
                        speak_text(get_text("analysisComplete").format(
                            disease_name=disease_name,
                            confidence=f"{confidence*100:.0f} percent"
                        ), st.session_state.current_language)
                        st.session_state.show_solutions = True # Automatically show solutions after analysis
                else:
                    st.warning(get_text("invalidImageWarning"))
                    speak_text(get_text("invalidImageWarning"), st.session_state.current_language)
            else:
                st.warning(get_text("selectImagePrompt"))
                speak_text(get_text("selectImagePrompt"), st.session_state.current_language)

    if st.session_state.disease_info and st.session_state.show_solutions:
        st.markdown(f"<div class='analysis-section'>", unsafe_allow_html=True)
        st.markdown(f"<h3>{get_text('analysisTitle')}</h3>", unsafe_allow_html=True)
        st.write(f"**{get_text('identifiedDisease')}:** {st.session_state.disease_info['name']}")
        st.write(f"**{get_text('confidence')}:** {st.session_state.disease_info['confidence']*100:.2f}%")

        disease_details = st.session_state.disease_info['details']
        if disease_details:
            st.subheader(get_text('symptoms'))
            st.write(disease_details.get('symptoms', 'N/A'))

            st.subheader(get_text('chemicalTreatment'))
            st.write(disease_details.get('chemical_solution', 'N/A'))

            st.subheader(get_text('organicTreatment'))
            st.write(disease_details.get('organic_solution', 'N/A'))

            st.subheader(get_text('prevention'))
            st.write(disease_details.get('prevention_tips', 'N/A'))
        else:
            st.info("No detailed information available for this disease in the database.")
        st.markdown(f"</div>", unsafe_allow_html=True)

with col2:
    st.markdown(f"<h3>{get_text('voiceAssistantTitle')}</h3>", unsafe_allow_html=True)
    st.markdown(f"<div class='chat-container'>", unsafe_allow_html=True)
    for i, msg in enumerate(st.session_state.chat_history):
        if "**You:**" in msg:
            st.markdown(f"<p class='chat-message user'>{msg}</p>", unsafe_allow_html=True)
        else:
            st.markdown(f"<p class='chat-message assistant'>{msg}</p>", unsafe_allow_html=True)
    st.markdown(f"</div>", unsafe_allow_html=True)

    # The key for st.text_input must be unique and consistent
    # This line reads the current value of the text input
    command_input_value = st.text_input(get_text("typeCommand"), key="command_input")

    # Attach the callback function to the button
    # The on_click callback will be executed when the button is pressed
    st.button("Send Command", on_click=handle_command_and_clear)

    st.markdown("---")
    st.markdown(f"**{get_text('voiceCommandsList')}**")


st.markdown(f"<p style='text-align: center; margin-top: 3em; color: #6c757d;'>{get_text('footerText')}</p>", unsafe_allow_html=True)
